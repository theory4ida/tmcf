<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Daniel Archambault">
<meta name="author" content="Roger Beecham">
<meta name="author" content="Andrew Gelman">
<meta name="author" content="Jessica Hullman">
<meta name="author" content="Edwin Pos">
<meta name="dcterms.date" content="2024-06-25">
<meta name="description" content="Some thoughts arising from TMCF 2024 workshop at the Turing Institute.">

<title>TMCF 2024 - Some risks and opportunities of automated data analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: #f8f9fa;
      }

      .quarto-title-block .quarto-title-banner {
        color: #f8f9fa;
background: #495057;
      }
</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">TMCF 2024</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../challenge/"> 
<span class="menu-text">Challenge</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../programme/"> 
<span class="menu-text">Programme</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../lecture/"> 
<span class="menu-text">Public Lecture</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../team/"> 
<span class="menu-text">Team</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
    <a href="https://twitter.com/gisruk/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-twitter"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Some risks and opportunities of automated data analysis</h1>
                  <div>
        <div class="description">
          Some thoughts arising from TMCF 2024 workshop at the Turing Institute.
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://blogs.ncl.ac.uk/nova/">Daniel Archambault</a> </p>
               <p><a href="https://www.roger-beecham.com/">Roger Beecham</a> </p>
               <p><a href="http://www.stat.columbia.edu/~gelman/">Andrew Gelman</a> </p>
               <p><a href="http://users.eecs.northwestern.edu/~jhullman/">Jessica Hullman</a> </p>
               <p><a href="https://www.uu.nl/staff/ETPos">Edwin Pos</a> </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 25, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-human-directed-extreme" id="toc-the-human-directed-extreme" class="nav-link" data-scroll-target="#the-human-directed-extreme">The human-directed extreme</a></li>
  <li><a href="#the-fully-automated-extreme" id="toc-the-fully-automated-extreme" class="nav-link" data-scroll-target="#the-fully-automated-extreme">The fully automated extreme</a></li>
  <li><a href="#charting-a-generalized-path-through-extremes-of-y" id="toc-charting-a-generalized-path-through-extremes-of-y" class="nav-link" data-scroll-target="#charting-a-generalized-path-through-extremes-of-y">Charting a generalized path through extremes of <span class="math inline">\(y\)</span></a></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions">Conclusions</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>We have all been there: you have your research question, you’ve gathered your dataset, and you are ready to start digging. Or perhaps you only have a question and are wondering how you could answer it in the first place given all the options available. Ever since the invention of data analysis, the human analyst has held the primary role of thinking, deciding and analyzing. At the same time, there has been a steady progression toward automating parts of statistical workflow that are better done by machines, such as calculation. With impressive recent advancements in general purpose intelligent assistants like chatbots, we are in a better position than ever to imagine what an intelligent assistant who acts as a helpful collaborator during data analysis might look like. These new possibilities provide an opportunity to reflect on the ideal interaction between statistical tools and human knowledge. What are the risks involved with increasing amounts of automation in data analysis steps like problem specification, data collection, model specification and selection, and interpretation of results? What are the opportunities? How can we ensure that the sum of human knowledge and AI prediction in data analysis will be more than its parts?</p>
<p>To formalize the problem slightly, one could say that data analysis has traditionally involved applying some sequence of operations on data (e.g., reductions or visualizations) which we shall express as functions <span class="math inline">\(f = (f_1, f_2, …, f_n)\)</span> to data <span class="math inline">\(D\)</span>, each of which generates some intermediate output <span class="math inline">\(y_i = f_i(D)\)</span> to produce some ultimate knowledge output or interpretation <span class="math inline">\(K = f\)</span><span class="math inline">\(_{human}(y)\)</span>, where <span class="math inline">\(f_{human}\)</span> represents a human processing <span class="math inline">\(y = (y_1, y_2, …, y_n)\)</span>. For example, a conventional visual analytics workflow involves a human selecting and applying to data some set of queries or operations <span class="math inline">\(f(D)\)</span> (which might consist of filters, aggregations, regressions, etc.), then interpreting the output of these functions to produce some interpretation or decision <span class="math inline">\(K\)</span>.</p>
<p>As we consider how this simple formulation changes with increasing levels of automation, we propose this gives rise to a spectrum. On the one end you have a human-directed extreme, such as in conventional visual analytics (Keim et al.&nbsp;2008), where the human has chosen the specific functional form of the members of <span class="math inline">\(f\)</span> to apply to the data given their prior knowledge to find <span class="math inline">\(K\)</span>, and automation is involved primarily to perform what would otherwise be tedious calculations.</p>
<p>In the current age of technological development, where products like ChatGPT are <a href="https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt">promoted for data analysis</a>, from insight discovery to communication, we are closer to being able to imagine the other extreme of this spectrum: fully automated data analysis. In this case, the human only asks the question or provides a goal and optionally some data <span class="math inline">\(D\)</span>. The remainder of the process is automated, concluding with the machine presenting its interpretation <span class="math inline">\(K\)</span> (i.e., <span class="math inline">\(K=f_{assistent} (y)\)</span>). The human is not directly involved in selecting <span class="math inline">\(f\)</span> nor in processing the intermediate outputs of <span class="math inline">\(y\)</span>. Consequently, the selected f may not be interpretable to a human in the sense of being explainable via human-meaningful parameters.</p>
<p>Although it may seem to some readers to be immediately apparent that removing the human from data science is a bad idea, it is not at all clear that the current extent of automation in data analysis workflows is sufficient. Integrating more machine intelligence may help address human limitations we have had no choice but to accept in data analysis. For example, the human will be limited by their own experience, and may only be able to see a limited set of all the possible operations or functions that could be applied. Or, information processing biases may lead them to misperceive <span class="math inline">\(y\)</span>, resulting in a non-optimal <span class="math inline">\(K\)</span> even if their selection of <span class="math inline">\(f\)</span> was in fact optimal. There would seem to be many ways that using AI could improve analysis outputs in light of the limited knowledge and experience that any human analyst might have.</p>
<p>We propose that thinking about the spectrum from fully human-driven to fully machine-driven analysis is helpful in several ways. First, by explicitly reflecting on what the ideal role of the human is in data analysis, we gain insight into what aspects of data analysis we think are truly human or non-automatable, and which are better given to the machine. Second, as research and practice increasingly makes use of predictive modeling, we are in a better position to apply our expertise on statistical modeling to design better futures for interactive data analysis. Below we explore this spectrum from its two extremes.</p>
</section>
<section id="the-human-directed-extreme" class="level2">
<h2 class="anchored" data-anchor-id="the-human-directed-extreme">The human-directed extreme</h2>
<p>At one end of the spectrum, the human selects the functions to be applied, processes the outputs of those functions more or less manually (i.e., without necessarily using formal decision rules), and maps the beliefs that they form to an interpretation. We assume that the human has access to visual analytics processes and technology (Keim et al., 2008). By this we mean that the human does not perform the calculation themselves (we aren’t worried about mathematical errors in generating the individual <span class="math inline">\(i\)</span>), and they have access to visual analytics systems that perform the calculations and present the answers in a visual form for interpretation through <span class="math inline">\(f_{human}\)</span>. We assume the human has some level of understanding of how the particular set of functions work and what they mean. In other words, <span class="math inline">\(f\)</span> consists of interpretable operations, such as parameterized functions <span class="math inline">\(f_{theta}\)</span> where theta is considered meaningful to the human, or simple deterministic functions like finding the maximum of data series. It is worth noting that despite the interpretability of the operations applied, how exactly the human processes the available information (i.e., <span class="math inline">\(f_{human}\)</span>) can be thought of as a black box of sorts, as the generation of <span class="math inline">\(y\)</span> is guided implicitly by the previous experience and domain specific knowledge of the human in addition to the data. It is assumed that the human knows how to best apply their domain knowledge in this scenario.</p>
<p>We can loosely analogize the learning problem to Bayesian decision theory for the purpose of identifying failure points. Assume some high level learning goal given some observed dataset; for example, an analyst hired by a large school district might be investigating the question, What factors explain the dip in high school math performance between 2018 and 2020? While normally in applied Bayesian analysis we would focus on how posterior beliefs about the some parameters deemed meaningful are arrived at within the context of some particular model specification, here we will instead think of the knowledge gained from the entire analysis workflow as resulting from some combination of the analyst’s prior knowledge and beliefs, the data at hand, and modeling assumptions. Assume for example that what the analyst finds is intended to inform the school district’s decision about what to invest next year’s budget in. The human analyst will likely bring some relevant domain knowledge (prior beliefs) on which variables are likely to matter and how much, how they should model the data to achieve their goals, what aspects of context should influence their interpretation, etc. For example, maybe they have prior experience on factors that predict high school test scores, biases that exist in available data, contextual knowledge about the specific school district, etc. What they know about such problems will influence the statistical modeling approach they select (e.g., a multiple regression predicting 11th grade standardized math test performance from some particular set of covariates). The output of the models and operations they apply inform their posterior beliefs about which factors influence student performance and how this information should inform a decision.</p>
<p>If the analyst were fully Bayesian, they would optimally combine the new information they learn with their prior beliefs to arrive at posterior beliefs, then select the utility maximizing interpretation or decision from a space of possible decisions. But a number of things can go wrong when dealing with boundedly rational agents. The analyst’s prior knowledge itself might be biased or incomplete, leading them to analyze the wrong data, fail to select an appropriate set of operations <span class="math inline">\(f\)</span>, etc. They might make bad assumptions in model specification or selection, leading to misleading modeling outputs. They might overconstrain their analysis based on their priors (or discount them too easily) by taking advantage of degrees of freedom, for example if they are predisposed to prefer a certain interpretation leading to biased beliefs they might settle on a particular fitted model because it aligns with these preferences. They might arrive at the wrong interpretation or decision in light of their beliefs.</p>
<p>On the other hand, there may be advantages to the fully human case. The human understands exactly what was applied in <span class="math inline">\(f\)</span> and drives the interpretation of <span class="math inline">\(y\)</span>, enabling them to apply domain knowledge in a flexible, unscripted way. Their understanding and experience with the functions or models they apply makes it easier for them to debug issues, and they may feel more confident about the interpretation they ultimately arrive at. They have the ability to reformulate the goals and problem upon viewing results at any point, for example if they originally failed to consider some important data. More broadly, if the purpose of most data science is to generate insight from data for human purposes, in the fully human-driven case we are 100% sure that data science is happening as every step was done by and consumed by the human, providing an opportunity for understanding, critique, and reconsideration at each step.</p>
</section>
<section id="the-fully-automated-extreme" class="level2">
<h2 class="anchored" data-anchor-id="the-fully-automated-extreme">The fully automated extreme</h2>
<p>At the fully automated extreme, the human provides an analysis goal and optionally data. When considering the Keim et al.&nbsp;model of visual analytics (Keim et al.&nbsp;2008), the assistant has complete control over all stages, including automated processing of knowledge. In the extreme, the assistant simply returns the answer, <span class="math inline">\(K\)</span>, without any justification or provenance of the analysis. For the purposes of this post, we assume the assistant optimally combines what can be gleaned from all available prior statistical and scientific modeling examples in an autoregressive framework in which its task is to predict the most appropriate sequence of steps given the human’s prompt.</p>
<p>Several risks arise from the training constraints on the assistant. For example, one risk arises from how the assistant’s suggestions will be constrained by what it has seen, which in the best case consists of all prior observed statistical analyses. The model cannot necessarily suggest an altogether new form of analysis unless it in some way represents a combination of previous observed analyses. This raises the question of whether and when we might expect completely new analysis paradigms to emerge which could not somehow be reconstitutions of existing ideas.</p>
<p>Relatedly, the assistant is constrained to suggesting what is most probable. Ask any statistician if they expect frequencies within a corpus representing all historical examples of statistical analysis to capture the appropriateness of a given analysis path and they will answer with a resounding no. If ritualistic choice of models and interpretation of results is a problem in the fully human directed case, then any agent restricted to optimizing an autoregressive objective over some corpus of training data has the potential to miss something more appropriate but less prevalent in the training data. To some extent modern machine learning pipelines can overcome these biases through processes like fine-tuning, where a small amount of preference data is collected after training an unsupervised foundation model and used to adjust the conditional distribution of the model’s output. However, fine-tuning for particular cases implies a form of interaction that would seem to contradict the extreme fully-automated case: if we expect analyses to improve through interaction to obtain further context- or expert-specific input, we would seem to be advocating for an interactive dialogue between the human user and the assistant.</p>
<p>Relatedly, the fully automated scenario assumes that the human, at the time of prompting, is able to specify their true analysis goal, and in doing so will know how to customize the prompt to contain any relevant domain knowledge they have. But this begins to sound a lot like our trust that the human knows best how to apply their knowledge in the fully human-driven case. Is this reasonable? Or does the real human analyst require intermediate outputs along the way in order to cue lessons from their prior knowledge and experience? Consider how often real analysis workflows involve a shifting of direction. Upon viewing representations of our data in early Exploratory Data Analysis, we might realize our misconceptions of what it contained. Perhaps the fidelity of information we thought we could capture (and which we need to achieve our analysis goals) is simply not possible, and we must rethink our questions altogether. Or, we might realize upon reviewing model diagnostics that there is little signal in the variables we have collected, but have an idea of what other features we could collect. Can we imagine data analysis without such flexibility? Is it possible that an assistant could anticipate such changes in direction? The answer in the extreme case is simply returned without any reason or process to derive the answer, hence no obvious recourse for the human to take further action. Thus, knowledge is gained in some sense if they choose to trust it, but that might be hard.</p>
</section>
<section id="charting-a-generalized-path-through-extremes-of-y" class="level2">
<h2 class="anchored" data-anchor-id="charting-a-generalized-path-through-extremes-of-y">Charting a generalized path through extremes of <span class="math inline">\(y\)</span></h2>
<p>The above reflections suggest the ideal amount of machine assistance in data analysis will lie somewhere between the two extremes, and may differ depending on the expertise of the particular human and the specific context. However, we could say that the goal in finding the sweet spot is to identify the points where the human’s imagination holds them back from realizing a better path. If good statistical practice involves judicious use of computation to extend the human’s ability to imagine possible outcomes (e.g., alternative values for a statistic resulting from bias or sampling error, counterfactuals in causal inference, equivalently performing models in machine learning, etc.), a computational assistant who can entertain many models or theories simultaneously provides opportunities to “amplify” human cognition, a stated goal of visualization.</p>
<p>But how much should an assistant prompt the human to imagine outside their comfort zone? Attempting to design the optimal human-machine pairing naturally motivates reflection on the extent to which we want data-driven science to be pluralistic, allowing for different beliefs and conventions when it comes to how to best learn from data. Consider a familiar tension in the field of data analysis between inference, theory and explanation, and prediction. Researchers and practitioners in different fields and domains vary in how much they value each. It would seem that an optimal assistant would need to adjust to the specific problem in ways congruent with domain-specific values. In social and natural science applications, the assistant might, for example, behave like a scientist from those traditions, where the generated y (and consequently <span class="math inline">\(K\)</span> derived from <span class="math inline">\(y\)</span>) is grounded in substantive theory. In Operations research where prediction is typically the goal, we might judge possible outputs purely in terms of best out-of-sample performance, leading to a much more quantitative (minimal) inspection of <span class="math inline">\(y\)</span> to arrive at <span class="math inline">\(K\)</span>.</p>
<p>Paradigmatic differences leave us with many questions around how the assistant should be constrained or configured to realize the goals of scientific knowledge development. We should think about what level of constraints are tolerable and ultimately desirable for learning in a domain, which is a question about how comfortable we are with letting an assistant push us outside our comfort zones as scientists. If the social or natural scientist fine-tunes or otherwise configures the assistant only in a way that reproduces existing practice, the risk is simply reproducing the status quo. What level of “expanded” imagination is desirable for the purpose of scientific progress? For example, should researchers working in domains that prioritize explanatory approaches be given recommendations informed by predictive modeling, as proposed by Hofman et al.&nbsp;(2021) in advocating for integrative modeling? Are there unified goals, constraints or features of analysis – ways of evaluatin and thinking about the y that gives rise to <span class="math inline">\(K\)</span> – that are independent of domain, or are we ultimately constrained to work only within a particular modeling paradigm because historically boundaries have existed? To what extent is explicit design toward achieving specific features/goals of scientific analysis and different standards of evidence (Hofman et al., 2021) useful in constraining the assistant?</p>
<p>For example, to what extent should the ideal pairing of the human and machine for data science seek to prioritize:</p>
<ul>
<li><strong>Substantive theory</strong> – Extent to which the <span class="math inline">\(K\)</span> that is derived supports, validates and extends knowledge.</li>
<li><strong>Reproducibility and transfer</strong> – Extent to which <span class="math inline">\(K\)</span> is reproducible - for example, is it invariant under perturbations we do not believe should substantively change results, such as slight variations in how the assistant is called? Notions of replicability may also matter: when should a closely related analysis on similar datasets in the same domain produce an analogous result?<br>
</li>
<li><strong>Transparency</strong> – Extent to which <span class="math inline">\(K\)</span> that can be easily understood and interrogated.</li>
<li><strong>Coverage and generalizability</strong> – Extent to which <span class="math inline">\(K\)</span> encompasses a narrow or wide range of settings (contexts, scales, etc.).</li>
<li><strong>Expansiveness</strong> – Extent to which <span class="math inline">\(K\)</span> extends imagination, or that enables the analyst to push beyond bounds of inherited modeling and data paradigms.</li>
</ul>
<p>Different domains and use cases might naturally have different weightings on each of these features, leading to different modeling paradigms. Where do we find ourselves on the spectrum, and to what extent might we expect an intelligent assistant to be informed by knowledge of other points along it, so as to push analysts in a given domain outside of their comfort zone?</p>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>There are many other risks and benefits of the human-directed and automated extremes than those discussed above. However, several themes arise even from our partial treatment. One is that it seems unlikely that the optimal analysis approach is either fully human-directed (with the primary form of automation being calculation as assumed above) or nearly fully automated, with the human providing only the high level goal and optionally, some data. Without any visibility into how <span class="math inline">\(K\)</span> was produced, the human has no opportunity to apply knowledge that is not contained in the training data to debug operations chosen by the machine. They may not feel confident in their results, and their lack of insight into how they were reached may prevent them from applying the knowledge that is output, leading to a question of whether it is knowledge at all.</p>
<p>At the same time, a machine that can run many analyses simultaneously, including approaches the human may not know of or be familiar with, has the potential to result in much more informed interpretations of data. There are many blindspots in human analysis. Forms of model multiplicity (the fact that we can get the same model fit or performance from models that imply very different interpretations of a phenomena) and sources of uncertainty (e.g., about how good our assumptions are) are routinely overlooked. In general, it is unlikely that either extreme will be sufficient, prompting a number of questions about how explicitly an analysis assistant should prompt a human analyst to think more expansively than they otherwise might. Key challenges lie in identifying when, how, and why to elicit human knowledge, so as to show the analyst what they may miss, and how to communicate results from potentially non-human interpretable operations in ways that humans can understand. In the current age of technological advancement with increasingly advanced automated methods we expect the sum will indeed be more than its parts.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>Hofman, J.M., Watts, D.J., Athey, S. <em>et al.</em> Integrating explanation and prediction in computational social science. <em>Nature</em> 595, 181–188 (2021). doi: <a href="https://doi.org/10.1038/s41586-021-03659-0">10.1038/s41586-021-03659-0</a></p>
<p>Hullman, J., and Gelman, A. (2021). Comparing human to automated statistics. Section 6 of Designing for interactive exploratory data analysis requires theories of graphical inference, Harvard Data Science Review 3 (3).</p>
<p>Hullman, J., Holtzman, A., and Gelman, A. (2023). Artificial intelligence and aesthetic judgment. http://stat.columbia.edu/~gelman/research/unpublished/AI_aesthetic_judgment.pdf</p>
<p>Keim, D., Andrienko, G., Fekete, JD., Görg, C., Kohlhammer, J., Melançon, G. (2008). Visual Analytics: Definition, Process, and Challenges. In: Kerren, A., Stasko, J.T., Fekete, JD., North, C. (eds) Information Visualization. Lecture Notes in Computer Science, vol 4950. Springer, Berlin, Heidelberg. doi: <a href="https://doi.org/10.1007/978-3-540-70956-5_7">10.1007/978-3-540-70956-5_7</a></p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{archambault2024,
  author = {Archambault, Daniel and Beecham, Roger and Gelman, Andrew
    and Hullman, Jessica and Pos, Edwin},
  title = {Some Risks and Opportunities of Automated Data Analysis},
  date = {2024-06-25},
  url = {https://theory4ida.github.io/tmcf/posts/01-models/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-archambault2024" class="csl-entry quarto-appendix-citeas" role="listitem">
Archambault, Daniel, Roger Beecham, Andrew Gelman, Jessica Hullman, and
Edwin Pos. 2024. <span>“Some Risks and Opportunities of Automated Data
Analysis.”</span> June 25, 2024. <a href="https://theory4ida.github.io/tmcf/posts/01-models/">https://theory4ida.github.io/tmcf/posts/01-models/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/theory4ida\.github\.io\/tmcf\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/theory4ida/tmcf">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>